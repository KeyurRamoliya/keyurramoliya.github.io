---
layout: post
title: "Thoughts on AI Business Models"
categories:
- business
tags:
- Artificial Intelligence
- AI
- Business Models
- Machine Learning
- Deep Learning
- Data Science
- Monetization
- Value Proposition
- Business Strategy
- Revenue Streams
- AI Applications
- AI Services
- AI Products
- AI Platforms
- AI Marketplaces
- AI Consulting
- AI Training
- AI Research
- AI Ethics
- Apple
- OpenAI
- Apple Intelligence
---

The Apple AI (or “Apple Intelligence”) release highlights an ongoing development in artificial intelligence, with tech giants exploring different revenue strategies.

|![AppleIntelligence](/assets/images/2024/06/19/AppleIntelligence.png)|
|:--:| 
|*From Apple*|

There is an interesting pattern appears across these companies’ approaches. Advanced AI models from OpenAI, Google, Anthropic, and Microsoft come with a monthly subscription fee or API access for a usage-based charge.

Well, some advanced AI capabilities are being offered for free, including Copilot and ChatGPT-4o. Apple seems to be starting with a free service but may consider charging in the future.

This reflects the industry’s search for sustainable business models, although significant funding is available. Trust is crucial for AI companies’ success, with concerns around privacy and unclear practices causing distrust.

Apple takes privacy a step further by ensuring that even if desired, it could never access personal data.

But in the show, in a few minutes,

they went from:

**“even if a company says it’s not misusing your data, you are unable to verify their claim.”**

to:

**“in some cases, you need models that are larger than what fits in your pocket today.”**

So, only local AI on the user’s device can access personal information, while data sent to the cloud is encrypted, processed anonymously, and instantly erased, making it challenging to intercept.

With its limited use cases and strong privacy focus, Apple’s approach represents an “ethical” use of AI, though details about its training data are unclear.

Time will tell if this approach is enough to increase public trust in AI.
